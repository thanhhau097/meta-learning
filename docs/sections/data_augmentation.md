# data_augmentation
In supervised learning it is common to improve generalization by synthesizing more training data through label-preserving transformations on the ex- isting data. The data augmentation operation is wrapped up in optimization steps of the inner problem Eq. 6, and is conventionally hand-designed. However, when Ï‰ defines the data augmentation strategy, it can be learned by the outer optimization in Eq. 5 in order to maximize validation performance [133]. Since augmentation operations are typi- cally non-differentiable, this requires reinforcement learning [133], discrete gradient-estimators [134], or evolutionary [135] methods. An open question is whether powerful GAN- based data augmentation methods [136] can be used in
inner-level learning and optimized in outer-level learning.
<!-- REFERENCE -->


<details>
<summary>[133] AutoAugment: Learning Augmentation Policies From Data</summary>
<br>
<!-- (autoaugment_learning_augmentation_policies_from_data.md) -->

# autoaugment_learning_augmentation_policies_from_data.md

<!-- REFERENCE -->


[AutoAugment: Learning Augmentation Policies From Data](../papers/autoaugment_learning_augmentation_policies_from_data.md)

</details>



<details>
<summary>[136] Data Augmentation Generative Adversarial Networks</summary>
<br>
<!-- (data_augmentation_generative_adversarial_networks.md) -->

# data_augmentation_generative_adversarial_networks.md

<!-- REFERENCE -->


[Data Augmentation Generative Adversarial Networks](../papers/data_augmentation_generative_adversarial_networks.md)

</details>



<details>
<summary>[134] DADA: Differentiable Automatic Data Augmentation</summary>
<br>
<!-- (dada_differentiable_automatic_data_augmentation.md) -->

# dada_differentiable_automatic_data_augmentation.md

<!-- REFERENCE -->


[DADA: Differentiable Automatic Data Augmentation](../papers/dada_differentiable_automatic_data_augmentation.md)

</details>



<details>
<summary>[135] Model Vulnerability To Distributional Shifts Over Image Transformation Sets</summary>
<br>
<!-- (model_vulnerability_to_distributional_shifts_over_image_transformation_sets.md) -->

# model_vulnerability_to_distributional_shifts_over_image_transformation_sets.md

<!-- REFERENCE -->


[Model Vulnerability To Distributional Shifts Over Image Transformation Sets](../papers/model_vulnerability_to_distributional_shifts_over_image_transformation_sets.md)

</details>

