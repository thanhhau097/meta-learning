# discussion_interpretable_symbolic_representations
A cross-cutting distinction that can be made across many of the meta-representations discussed above is between unin- terpretable (sub-symbolic) and human interpretable (sym- bolic) representations. Sub-symbolic representations such as when ω parameterizes a neural network [78], are more commonly studied and make up the majority of studies cited above. However, meta-learning with symbolic rep- resentations is also possible, where ω represents symbolic functions that are human readable as a piece of program code [89], comparable to Adam [102]. Rather than neural loss functions [44], one can train symbolic losses ω that are defined by an expression comparable to cross-entropy [115]. One can also meta-learn new symbolic activations [151] that outperform standards such as ReLU. As these meta- representations are non-smooth, the meta-objective is non- differentiable and is harder to optimize (see Section 4.2). So the upper optimization for ω typically uses RL [89] or evolutionary algorithms [115]. However, symbolic represen- tations may have an advantage [89], [115], [151] in their ability to generalize across task families. I.e., to span wider distributions p(T) with a single ω during meta-training, or to have the learned ω generalize to an out of distribution task during meta-testing (see Section 6).

<!-- REFERENCE -->


<details>
<summary>[44] Feature-Critic Networks For Heterogeneous Domain Generalization</summary>
<br>
<!-- (feature_critic_networks_for_heterogeneous_domain_generalization.md) -->

# feature_critic_networks_for_heterogeneous_domain_generalization.md

<!-- REFERENCE -->


[Feature-Critic Networks For Heterogeneous Domain Generalization](../papers/feature_critic_networks_for_heterogeneous_domain_generalization.md)

</details>



<details>
<summary>[115] Improved Training Speed, Accuracy, And Data Utilization Through Loss Function Optimization</summary>
<br>
<!-- (improved_training_speed_accuracy_and_data_utilization_through_loss_function_optimization.md) -->

# improved_training_speed_accuracy_and_data_utilization_through_loss_function_optimization.md

<!-- REFERENCE -->


[Improved Training Speed, Accuracy, And Data Utilization Through Loss Function Optimization](../papers/improved_training_speed_accuracy_and_data_utilization_through_loss_function_optimization.md)

</details>



<details>
<summary>[78] Learning To Learn By Gradient Descent By Gradient Descent</summary>
<br>
<!-- (learning_to_learn_by_gradient_descent_by_gradient_descent.md) -->

# learning_to_learn_by_gradient_descent_by_gradient_descent.md

<!-- REFERENCE -->


[Learning To Learn By Gradient Descent By Gradient Descent](../papers/learning_to_learn_by_gradient_descent_by_gradient_descent.md)

</details>



<details>
<summary>[102] Adam: A Method For Stochastic Optimization</summary>
<br>
<!-- (adam_a_method_for_stochastic_optimization.md) -->

# adam_a_method_for_stochastic_optimization.md

<!-- REFERENCE -->


[Adam: A Method For Stochastic Optimization](../papers/adam_a_method_for_stochastic_optimization.md)

</details>



<details>
<summary>[151] Searching For Activation Functions</summary>
<br>
<!-- (searching_for_activation_functions.md) -->

# searching_for_activation_functions.md

<!-- REFERENCE -->


[Searching For Activation Functions](../papers/searching_for_activation_functions.md)

</details>



<details>
<summary>[89] Neural Optimizer Search With Reinforcement Learning</summary>
<br>
<!-- (neural_optimizer_search_with_reinforcement_learning.md) -->

# neural_optimizer_search_with_reinforcement_learning.md

<!-- REFERENCE -->


[Neural Optimizer Search With Reinforcement Learning](../papers/neural_optimizer_search_with_reinforcement_learning.md)

</details>

